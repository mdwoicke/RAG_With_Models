{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdEptqcyiw-E"
      },
      "source": [
        "# List of Packages to Download\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-chroma\n",
        "!pip install langchain\n",
        "!pip install langchain_community\n",
        "!pip install langchainhub"
      ],
      "metadata": {
        "id": "9DluPJ8gi3ZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install --upgrade gpt4all"
      ],
      "metadata": {
        "id": "hcFr7Mnbj1Fj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langchain-huggingface"
      ],
      "metadata": {
        "id": "k1QprDoRmqz0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --quiet  langchain sentence_transformers"
      ],
      "metadata": {
        "id": "_RVVuicFqaLm"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPHSZPfJiw-F"
      },
      "source": [
        "# 1. Get a Data Loader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzvhxClqiw-F",
        "outputId": "889879a3-66d4-4741-84e6-bc95e35b386c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.document_loaders import WebBaseLoader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rnbw1kzCiw-G"
      },
      "outputs": [],
      "source": [
        "loader = WebBaseLoader(\"https://www.foxsports.com/nba/lebron-james-player-game-log?season=2023&seasonType=reg\")\n",
        "data = loader.load()\n",
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOf8W2IHiw-G"
      },
      "source": [
        "# 2. Convert data to Vector Database\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "1toJ3SPaiw-G"
      },
      "outputs": [],
      "source": [
        "from langchain.vectorstores import Chroma\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_model = HuggingFaceEmbeddings() #sentence-transformers/all-mpnet-base-v2"
      ],
      "metadata": {
        "id": "Y_iD186z0Cy8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Chroma.from_documents(documents=data, embedding=embeddings_model, persist_directory=\"./chroma_db\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrtCA-M20JNH",
        "outputId": "3494c49f-99db-4d90-b125-bc951e7d2b6b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langchain_community.vectorstores.chroma.Chroma at 0x79b89015a9e0>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxOE6JTeiw-G"
      },
      "source": [
        "# 3. Make a RAG pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "z3czNRmoiw-G"
      },
      "outputs": [],
      "source": [
        "from langchain_community.chat_models import ChatOllama\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain import hub\n",
        "from langchain_huggingface.llms import HuggingFacePipeline\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_id = \"Qwen/Qwen2-7B-Instruct\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id)\n",
        "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, max_new_tokens=100)\n",
        "hf = HuggingFacePipeline(pipeline=pipe)"
      ],
      "metadata": {
        "id": "kE3XhYXD0Sjv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = hf\n",
        "\n",
        "#uncomment if using ollama\n",
        "#llm = ChatOllama(model=\"qwen2\")\n",
        "\n",
        "prompt = hub.pull(\"rlm/rag-prompt\")\n",
        "vectorstore = Chroma(persist_directory=\"./chroma_db\", embedding_function=HuggingFaceEmbeddings())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQH6-Edb0oj_",
        "outputId": "e26fa4ad-4095-4f7d-dcc8-d9311490b783"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "        llm,\n",
        "        retriever=vectorstore.as_retriever(),\n",
        "        chain_type_kwargs={\"prompt\": prompt}\n",
        "    )"
      ],
      "metadata": {
        "id": "24kCxa6R1Lvx"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Who's stats are these\"\n",
        "result = qa_chain({\"query\": question })"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8l2jfE961NwD",
        "outputId": "438f1e6e-bc33-4af9-80ce-e742b352e534"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
            "  warn_deprecated(\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Number of requested results 4 is greater than number of elements in index 1, updating n_results = 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result[\"result\"]"
      ],
      "metadata": {
        "id": "Dxylc0kI3vqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hVOEtwTW2YR9"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}